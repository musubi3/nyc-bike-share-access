{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:14: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 1000000\n",
      "Columns: ['ride_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng'] ...\n",
      "Unique days in dataset: 35\n",
      "Target rows per day: 1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
      "/var/folders/bz/zpccx8jn6y181d_10s9j4k600000gn/T/ipykernel_44124/127949757.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after per-day stratified sampling: 44541\n",
      "Final sampled rows: 44541\n",
      "\n",
      "member_casual distribution (sampled):\n",
      "member_casual\n",
      "member    0.865135\n",
      "casual    0.134865\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "rideable_type distribution (sampled):\n",
      "rideable_type\n",
      "classic_bike     0.501426\n",
      "electric_bike    0.498574\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Date range in sampled data: 2022-12-14 to 2023-01-31\n",
      "\n",
      "Saved sampled dataset to: 202301-citibike-tripdata_sampled_50k.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===========================\n",
    "# 1. SETTINGS – EDIT THESE\n",
    "# ===========================\n",
    "csv_path = \"../data/202301-citibike-tripdata_1.csv\"   # <- your original file\n",
    "output_path = \"../data/202301-citibike-tripdata_sampled_50k.csv\"\n",
    "TARGET_ROWS = 50_000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ===========================\n",
    "# 2. LOAD DATA\n",
    "# ===========================\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist()[:10], \"...\")\n",
    "\n",
    "# Make sure the time column is parsed correctly\n",
    "df[\"started_at\"] = pd.to_datetime(df[\"started_at\"])\n",
    "\n",
    "# Add a pure date column (YYYY-MM-DD)\n",
    "df[\"date\"] = df[\"started_at\"].dt.date\n",
    "print(\"Unique days in dataset:\", df[\"date\"].nunique())\n",
    "\n",
    "# ===========================\n",
    "# 3. COMPUTE PER-DAY SAMPLE SIZE\n",
    "# ===========================\n",
    "n_days = df[\"date\"].nunique()\n",
    "rows_per_day = TARGET_ROWS // n_days  # floor division\n",
    "print(\"Target rows per day:\", rows_per_day)\n",
    "\n",
    "# ===========================\n",
    "# 4. STRATIFIED SAMPLING\n",
    "#    - for each day, sample ~rows_per_day rows\n",
    "#    - within each day, preserve proportions of\n",
    "#      member_casual and rideable_type\n",
    "# ===========================\n",
    "sampled_daily = []\n",
    "\n",
    "for day, day_df in df.groupby(\"date\"):\n",
    "    day_size = len(day_df)\n",
    "    if day_size == 0:\n",
    "        continue\n",
    "    \n",
    "    # fraction of that day's rows to sample\n",
    "    sample_frac = rows_per_day / day_size\n",
    "    sample_frac = min(sample_frac, 1.0)  # cannot exceed 100%\n",
    "    \n",
    "    day_sample = (\n",
    "        day_df\n",
    "        .groupby([\"member_casual\", \"rideable_type\"], group_keys=False)\n",
    "        .apply(lambda g: g.sample(frac=sample_frac, random_state=RANDOM_SEED))\n",
    "    )\n",
    "    \n",
    "    sampled_daily.append(day_sample)\n",
    "\n",
    "sampled_df = pd.concat(sampled_daily, ignore_index=True)\n",
    "print(\"Rows after per-day stratified sampling:\", len(sampled_df))\n",
    "\n",
    "# ===========================\n",
    "# 5. OPTIONAL: TRIM TO EXACTLY TARGET_ROWS\n",
    "# ===========================\n",
    "if len(sampled_df) > TARGET_ROWS:\n",
    "    sampled_df = sampled_df.sample(\n",
    "        n=TARGET_ROWS,\n",
    "        random_state=RANDOM_SEED\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "print(\"Final sampled rows:\", len(sampled_df))\n",
    "\n",
    "# Quick sanity checks (optional)\n",
    "print(\"\\nmember_casual distribution (sampled):\")\n",
    "print(sampled_df[\"member_casual\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nrideable_type distribution (sampled):\")\n",
    "print(sampled_df[\"rideable_type\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDate range in sampled data:\",\n",
    "      sampled_df[\"date\"].min(), \"to\", sampled_df[\"date\"].max())\n",
    "\n",
    "# ===========================\n",
    "# 6. SAVE TO CSV\n",
    "# ===========================\n",
    "sampled_df.to_csv(output_path, index=False)\n",
    "print(\"\\nSaved sampled dataset to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb9c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reloaded cleaned data, rows: 44265\n",
      "Date range in cleaned data: 2023-01-01 to 2023-01-31\n",
      "Rows after filtering to January 2023: 44265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E441DF12E01D900E</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-01 13:36:56.305</td>\n",
       "      <td>2023-01-01 13:59:16.036</td>\n",
       "      <td>5 Ave &amp; E 72 St</td>\n",
       "      <td>7100.07</td>\n",
       "      <td>5 Ave &amp; E 63 St</td>\n",
       "      <td>6904.06</td>\n",
       "      <td>40.772828</td>\n",
       "      <td>-73.966853</td>\n",
       "      <td>40.766368</td>\n",
       "      <td>-73.971518</td>\n",
       "      <td>casual</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D0C5B4E524A0B7FB</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-01 13:23:04.688</td>\n",
       "      <td>2023-01-01 13:41:52.653</td>\n",
       "      <td>3 Ave &amp; E 72 St</td>\n",
       "      <td>7028.04</td>\n",
       "      <td>2 Ave &amp; E 31 St</td>\n",
       "      <td>6197.02</td>\n",
       "      <td>40.769943</td>\n",
       "      <td>-73.960607</td>\n",
       "      <td>40.742909</td>\n",
       "      <td>-73.977061</td>\n",
       "      <td>casual</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA2F79F3298E68CA</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-01 12:24:57.138</td>\n",
       "      <td>2023-01-01 12:48:13.620</td>\n",
       "      <td>Fulton St &amp; Broadway</td>\n",
       "      <td>5175.08</td>\n",
       "      <td>Fulton St &amp; Broadway</td>\n",
       "      <td>5175.08</td>\n",
       "      <td>40.711066</td>\n",
       "      <td>-74.009447</td>\n",
       "      <td>40.711066</td>\n",
       "      <td>-74.009447</td>\n",
       "      <td>casual</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4E343A88DF619C04</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-01 10:54:09.455</td>\n",
       "      <td>2023-01-01 11:42:20.771</td>\n",
       "      <td>5 Ave &amp; E 72 St</td>\n",
       "      <td>7100.07</td>\n",
       "      <td>5 Ave &amp; E 72 St</td>\n",
       "      <td>7100.07</td>\n",
       "      <td>40.772828</td>\n",
       "      <td>-73.966853</td>\n",
       "      <td>40.772828</td>\n",
       "      <td>-73.966853</td>\n",
       "      <td>casual</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97361E0404890052</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-01 13:53:06.154</td>\n",
       "      <td>2023-01-01 14:13:22.392</td>\n",
       "      <td>Centre St &amp; Chambers St</td>\n",
       "      <td>5207.01</td>\n",
       "      <td>N Moore St &amp; Hudson St</td>\n",
       "      <td>5470.02</td>\n",
       "      <td>40.712733</td>\n",
       "      <td>-74.004607</td>\n",
       "      <td>40.719961</td>\n",
       "      <td>-74.008443</td>\n",
       "      <td>casual</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44260</th>\n",
       "      <td>3DC1F545A9049C0D</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-31 19:29:18.975</td>\n",
       "      <td>2023-01-31 19:35:18.405</td>\n",
       "      <td>E 80 St &amp; 2 Ave</td>\n",
       "      <td>7121.02</td>\n",
       "      <td>E 91 St &amp; 2 Ave</td>\n",
       "      <td>7286.01</td>\n",
       "      <td>40.773914</td>\n",
       "      <td>-73.954395</td>\n",
       "      <td>40.781153</td>\n",
       "      <td>-73.949630</td>\n",
       "      <td>member</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44261</th>\n",
       "      <td>326C4939768CF3E8</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-31 17:06:59.853</td>\n",
       "      <td>2023-01-31 17:14:53.048</td>\n",
       "      <td>W 13 St &amp; 5 Ave</td>\n",
       "      <td>5947.04</td>\n",
       "      <td>E 2 St &amp; Avenue B</td>\n",
       "      <td>5515.02</td>\n",
       "      <td>40.735445</td>\n",
       "      <td>-73.994310</td>\n",
       "      <td>40.722174</td>\n",
       "      <td>-73.983688</td>\n",
       "      <td>member</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44262</th>\n",
       "      <td>7B2A676003FBE645</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-31 16:12:50.222</td>\n",
       "      <td>2023-01-31 16:46:07.273</td>\n",
       "      <td>Dean St &amp; Franklin Ave</td>\n",
       "      <td>4107.13</td>\n",
       "      <td>St Marks Pl &amp; 2 Ave</td>\n",
       "      <td>5669.10</td>\n",
       "      <td>40.677592</td>\n",
       "      <td>-73.955637</td>\n",
       "      <td>40.728419</td>\n",
       "      <td>-73.987140</td>\n",
       "      <td>member</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44263</th>\n",
       "      <td>0F659DF655960412</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-31 12:34:20.805</td>\n",
       "      <td>2023-01-31 12:38:17.233</td>\n",
       "      <td>E 48 St &amp; 5 Ave</td>\n",
       "      <td>6626.01</td>\n",
       "      <td>W 42 St &amp; 6 Ave</td>\n",
       "      <td>6517.08</td>\n",
       "      <td>40.757246</td>\n",
       "      <td>-73.978059</td>\n",
       "      <td>40.754920</td>\n",
       "      <td>-73.984550</td>\n",
       "      <td>member</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44264</th>\n",
       "      <td>264DBE9F75022206</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-31 16:37:19.823</td>\n",
       "      <td>2023-01-31 16:41:40.032</td>\n",
       "      <td>DeKalb Ave &amp; Vanderbilt Ave</td>\n",
       "      <td>4461.04</td>\n",
       "      <td>Willoughby St &amp; Ashland Pl</td>\n",
       "      <td>4587.02</td>\n",
       "      <td>40.689407</td>\n",
       "      <td>-73.968855</td>\n",
       "      <td>40.691780</td>\n",
       "      <td>-73.978770</td>\n",
       "      <td>member</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44265 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ride_id  rideable_type               started_at  \\\n",
       "0      E441DF12E01D900E   classic_bike  2023-01-01 13:36:56.305   \n",
       "1      D0C5B4E524A0B7FB   classic_bike  2023-01-01 13:23:04.688   \n",
       "2      BA2F79F3298E68CA   classic_bike  2023-01-01 12:24:57.138   \n",
       "3      4E343A88DF619C04   classic_bike  2023-01-01 10:54:09.455   \n",
       "4      97361E0404890052   classic_bike  2023-01-01 13:53:06.154   \n",
       "...                 ...            ...                      ...   \n",
       "44260  3DC1F545A9049C0D  electric_bike  2023-01-31 19:29:18.975   \n",
       "44261  326C4939768CF3E8  electric_bike  2023-01-31 17:06:59.853   \n",
       "44262  7B2A676003FBE645  electric_bike  2023-01-31 16:12:50.222   \n",
       "44263  0F659DF655960412  electric_bike  2023-01-31 12:34:20.805   \n",
       "44264  264DBE9F75022206  electric_bike  2023-01-31 16:37:19.823   \n",
       "\n",
       "                      ended_at           start_station_name  start_station_id  \\\n",
       "0      2023-01-01 13:59:16.036              5 Ave & E 72 St           7100.07   \n",
       "1      2023-01-01 13:41:52.653              3 Ave & E 72 St           7028.04   \n",
       "2      2023-01-01 12:48:13.620         Fulton St & Broadway           5175.08   \n",
       "3      2023-01-01 11:42:20.771              5 Ave & E 72 St           7100.07   \n",
       "4      2023-01-01 14:13:22.392      Centre St & Chambers St           5207.01   \n",
       "...                        ...                          ...               ...   \n",
       "44260  2023-01-31 19:35:18.405              E 80 St & 2 Ave           7121.02   \n",
       "44261  2023-01-31 17:14:53.048              W 13 St & 5 Ave           5947.04   \n",
       "44262  2023-01-31 16:46:07.273       Dean St & Franklin Ave           4107.13   \n",
       "44263  2023-01-31 12:38:17.233              E 48 St & 5 Ave           6626.01   \n",
       "44264  2023-01-31 16:41:40.032  DeKalb Ave & Vanderbilt Ave           4461.04   \n",
       "\n",
       "                 end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0                 5 Ave & E 63 St        6904.06  40.772828 -73.966853   \n",
       "1                 2 Ave & E 31 St        6197.02  40.769943 -73.960607   \n",
       "2            Fulton St & Broadway        5175.08  40.711066 -74.009447   \n",
       "3                 5 Ave & E 72 St        7100.07  40.772828 -73.966853   \n",
       "4          N Moore St & Hudson St        5470.02  40.712733 -74.004607   \n",
       "...                           ...            ...        ...        ...   \n",
       "44260             E 91 St & 2 Ave        7286.01  40.773914 -73.954395   \n",
       "44261           E 2 St & Avenue B        5515.02  40.735445 -73.994310   \n",
       "44262         St Marks Pl & 2 Ave        5669.10  40.677592 -73.955637   \n",
       "44263             W 42 St & 6 Ave        6517.08  40.757246 -73.978059   \n",
       "44264  Willoughby St & Ashland Pl        4587.02  40.689407 -73.968855   \n",
       "\n",
       "         end_lat    end_lng member_casual       date  \n",
       "0      40.766368 -73.971518        casual 2023-01-01  \n",
       "1      40.742909 -73.977061        casual 2023-01-01  \n",
       "2      40.711066 -74.009447        casual 2023-01-01  \n",
       "3      40.772828 -73.966853        casual 2023-01-01  \n",
       "4      40.719961 -74.008443        casual 2023-01-01  \n",
       "...          ...        ...           ...        ...  \n",
       "44260  40.781153 -73.949630        member 2023-01-31  \n",
       "44261  40.722174 -73.983688        member 2023-01-31  \n",
       "44262  40.728419 -73.987140        member 2023-01-31  \n",
       "44263  40.754920 -73.984550        member 2023-01-31  \n",
       "44264  40.691780 -73.978770        member 2023-01-31  \n",
       "\n",
       "[44265 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in cleaned data: 2023-01-01 00:00:00 to 2023-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv(output_path)\n",
    "print(\"\\nReloaded cleaned data, rows:\", len(cleaned_df))\n",
    "\n",
    "# Check start date and end date\n",
    "print(\"Date range in cleaned data:\",\n",
    "      cleaned_df[\"date\"].min(), \"to\", cleaned_df[\"date\"].max())\n",
    "\n",
    "# Only keep rows in January 2023\n",
    "cleaned_df[\"date\"] = pd.to_datetime(cleaned_df[\"date\"])\n",
    "cleaned_df = cleaned_df[\n",
    "      (cleaned_df[\"date\"] >= \"2023-01-01\") & (cleaned_df[\"date\"] < \"2023-02-01\")\n",
    "]\n",
    "print(\"Rows after filtering to January 2023:\", len(cleaned_df))\n",
    "display(cleaned_df)\n",
    "\n",
    "# Check start date and end date\n",
    "print(\"Date range in cleaned data:\",\n",
    "      cleaned_df[\"date\"].min(), \"to\", cleaned_df[\"date\"].max())\n",
    "\n",
    "cleaned_df.to_csv(\"../data/cleaned_df.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
